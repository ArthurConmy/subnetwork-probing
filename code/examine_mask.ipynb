{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "masked_state_dict = torch.load('masked_gpt2.pt')\n",
    "N=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2 into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "from transformer_lens.HookedTransformer import HookedTransformer\n",
    "gpt2_masked = HookedTransformer.from_pretrained(is_masked=True, model_name='gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens.ioi_dataset import IOIDataset\n",
    "\n",
    "ioi_dataset = IOIDataset(prompt_type=\"ABBA\", N=N, nb_templates=1)\n",
    "train_data = ioi_dataset.toks.long()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit_diff_from_ioi_dataset(\n",
    "    logits: torch.Tensor, tokens: torch.Tensor, mean=False,\n",
    "):\n",
    "    assert tokens.shape == (\n",
    "        N,\n",
    "        16,\n",
    "    ), tokens.shape  # TODO check this is not breaking things...\n",
    "    assert len(logits.shape) == 3, logits.shape\n",
    "\n",
    "    io_labels = tokens[:, 2]\n",
    "    s_labels = tokens[:, 4]\n",
    "\n",
    "    io_logits = logits[torch.arange(N), -2, io_labels]\n",
    "    s_logits = logits[torch.arange(N), -2, s_labels]\n",
    "\n",
    "    logit_diff = io_logits - s_logits\n",
    "    if mean:\n",
    "        return logit_diff.mean()\n",
    "    else:\n",
    "        return logit_diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks.0.attn.hook_q\n",
      "tensor(390.1159, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "blocks.0.attn.hook_k\n",
      "tensor(648.3994, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "blocks.0.attn.hook_v\n",
      "tensor(240.3886, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "blocks.1.attn.hook_q\n",
      "tensor(365.2684, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "blocks.1.attn.hook_k\n",
      "tensor(505.9655, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "blocks.1.attn.hook_v\n",
      "tensor(230.0281, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "blocks.2.attn.hook_q\n",
      "tensor(345.4847, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "blocks.2.attn.hook_k\n",
      "tensor(695.6668, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "blocks.2.attn.hook_v\n",
      "tensor(511.3076, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "blocks.3.attn.hook_q\n",
      "tensor(4.8455, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "blocks.3.attn.hook_k\n",
      "tensor(0., device='cuda:0', grad_fn=<NormBackward1>)\n",
      "blocks.3.attn.hook_v\n",
      "tensor(324.0270, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "blocks.4.attn.hook_q\n",
      "tensor(537.7574, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "blocks.4.attn.hook_k\n",
      "tensor(1061.2717, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "blocks.4.attn.hook_v\n",
      "tensor(428.8121, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "blocks.5.attn.hook_q\n",
      "tensor(707.5095, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "blocks.5.attn.hook_k\n",
      "tensor(572.4989, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "blocks.5.attn.hook_v\n",
      "tensor(594.6812, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "blocks.6.attn.hook_q\n",
      "tensor(0., device='cuda:0', grad_fn=<NormBackward1>)\n",
      "blocks.6.attn.hook_k\n",
      "tensor(0., device='cuda:0', grad_fn=<NormBackward1>)\n",
      "blocks.6.attn.hook_v\n",
      "tensor(483.1910, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "blocks.7.attn.hook_q\n",
      "tensor(0., device='cuda:0', grad_fn=<NormBackward1>)\n",
      "blocks.7.attn.hook_k\n",
      "tensor(0., device='cuda:0', grad_fn=<NormBackward1>)\n",
      "blocks.7.attn.hook_v\n",
      "tensor(614.1146, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "blocks.8.attn.hook_q\n",
      "tensor(414.9012, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "blocks.8.attn.hook_k\n",
      "tensor(533.4988, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "blocks.8.attn.hook_v\n",
      "tensor(502.5234, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "blocks.9.attn.hook_q\n",
      "tensor(0., device='cuda:0', grad_fn=<NormBackward1>)\n",
      "blocks.9.attn.hook_k\n",
      "tensor(0., device='cuda:0', grad_fn=<NormBackward1>)\n",
      "blocks.9.attn.hook_v\n",
      "tensor(651.7539, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "blocks.10.attn.hook_q\n",
      "tensor(802.5515, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "blocks.10.attn.hook_k\n",
      "tensor(975.1587, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "blocks.10.attn.hook_v\n",
      "tensor(752.2003, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "blocks.11.attn.hook_q\n",
      "tensor(0., device='cuda:0', grad_fn=<NormBackward1>)\n",
      "blocks.11.attn.hook_k\n",
      "tensor(0., device='cuda:0', grad_fn=<NormBackward1>)\n",
      "blocks.11.attn.hook_v\n",
      "tensor(647.4402, device='cuda:0', grad_fn=<NormBackward1>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(20.3451, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2_masked.load_state_dict(masked_state_dict)\n",
    "logit_diff_from_ioi_dataset(gpt2_masked(train_data), train_data, mean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# mask_dict = np.load('mask_dict.npy', allow_pickle=True).item()\n",
    "# mask_dict[\"0.0.q\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens import utils\n",
    "\n",
    "# def make_forward_hooks(nodes_to_mask):\n",
    "#     forward_hooks = []\n",
    "#     for layer in range(12):\n",
    "#         for head in range(12):\n",
    "#             for qkv in [\"q\", \"k\", \"v\"]:\n",
    "#                 mask_value = nodes_to_mask[f\"{layer}.{head}.{qkv}\"]\n",
    "#                 def head_ablation_hook(value, hook):\n",
    "#                     # print(f\"Shape of the value tensor: {value.shape}\")\n",
    "#                     value[:, :, layer, :] *= mask_value\n",
    "#                     return value\n",
    "\n",
    "#                 a_hook = (utils.get_act_name(qkv, int(head)), head_ablation_hook)\n",
    "#                 forward_hooks.append(a_hook)\n",
    "#     return forward_hooks\n",
    "\n",
    "from functools import partial \n",
    "\n",
    "def make_forward_hooks(nodes_to_mask):\n",
    "    forward_hooks = []\n",
    "    for layer in range(12):\n",
    "        for head in range(12):\n",
    "            for qkv in [\"q\", \"k\", \"v\"]:\n",
    "                mask_value = nodes_to_mask[f\"{layer}.{head}.{qkv}\"]\n",
    "                def head_ablation_hook(value, hook, head_idx, layer_idx, qkv_val, mask_value):\n",
    "                    # print(f\"Shape of the value tensor: {value.shape}\")\n",
    "                    # print(f\"{layer}.{head}.{qkv}\")\n",
    "                    value[:, :, head_idx, :] *= mask_value\n",
    "                    print(qkv_val, layer_idx, head_idx, torch.norm(value))\n",
    "                    print(\"transformer lens mask values\", mask_value)\n",
    "                    return value\n",
    "\n",
    "                a_hook = (utils.get_act_name(qkv, int(layer)), partial(head_ablation_hook, head_idx=head, layer_idx=layer, qkv_val=qkv, mask_value=mask_value))\n",
    "                forward_hooks.append(a_hook)\n",
    "    return forward_hooks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2 into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "# new_gpt2 = HookedTransformer.from_pretrained(is_masked=False, model_name='gpt2')\n",
    "# print(logit_diff_from_ioi_dataset(new_gpt2(train_data), train_data, mean=True))\n",
    "new_gpt2 = HookedTransformer.from_pretrained(is_masked=False, model_name='gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q 0 0 tensor(1025.2627, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 0 1 tensor(940.3607, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 0 2 tensor(907.1318, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 0 3 tensor(820.8910, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 0 4 tensor(751.3130, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 0 5 tensor(641.5286, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 0 6 tensor(591.0660, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 0 7 tensor(504.7794, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 0 8 tensor(410.9904, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 0 9 tensor(340.8100, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 0 10 tensor(241.9045, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 0 11 tensor(0., device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 0 0 tensor(1572.4468, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 0 1 tensor(1506.3849, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 0 2 tensor(1450.0033, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 0 3 tensor(1186.5457, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 0 4 tensor(1064.3646, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 0 5 tensor(971.7250, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 0 6 tensor(865.4471, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 0 7 tensor(657.7789, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 0 8 tensor(511.8061, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 0 9 tensor(406.7046, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 0 10 tensor(247.6138, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 0 11 tensor(0., device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 0 0 tensor(279.3705, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 0 1 tensor(269.8031, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 0 2 tensor(258.9207, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 0 3 tensor(252.0648, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 0 4 tensor(246.1294, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 0 5 tensor(236.2919, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 0 6 tensor(218.6015, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 0 7 tensor(205.7787, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 0 8 tensor(189.4418, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 0 9 tensor(143.0001, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 0 10 tensor(94.4284, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 0 11 tensor(0., device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 1 0 tensor(848.9522, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 1 1 tensor(807.4934, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 1 2 tensor(783.9784, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 1 3 tensor(757.1156, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 1 4 tensor(738.4771, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 1 5 tensor(666.8792, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 1 6 tensor(599.4614, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 1 7 tensor(564.7901, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 1 8 tensor(515.8875, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 1 9 tensor(461.4492, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 1 10 tensor(399.0471, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 1 11 tensor(0., device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 1 0 tensor(877.7585, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 1 1 tensor(832.7454, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 1 2 tensor(815.2481, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 1 3 tensor(805.1506, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 1 4 tensor(787.9374, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 1 5 tensor(729.0891, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 1 6 tensor(664.3770, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 1 7 tensor(622.8880, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 1 8 tensor(524.8979, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 1 9 tensor(377.9710, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 1 10 tensor(322.9201, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 1 11 tensor(0., device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 1 0 tensor(526.5428, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 1 1 tensor(501.5230, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 1 2 tensor(479.0062, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 1 3 tensor(464.6380, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 1 4 tensor(431.2971, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 1 5 tensor(394.2476, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 1 6 tensor(363.0460, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 1 7 tensor(308.9842, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 1 8 tensor(260.1785, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 1 9 tensor(194.5132, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 1 10 tensor(130.7053, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 1 11 tensor(0., device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 2 0 tensor(1108.0032, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 2 1 tensor(1077.2345, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 2 2 tensor(980.4236, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 2 3 tensor(930.0643, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 2 4 tensor(810.1735, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 2 5 tensor(733.8735, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 2 6 tensor(670.9884, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 2 7 tensor(591.7425, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 2 8 tensor(479.2372, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 2 9 tensor(350.5187, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 2 10 tensor(289.9093, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 2 11 tensor(0., device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 2 0 tensor(1777.1744, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 2 1 tensor(1742.5529, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 2 2 tensor(1550.4165, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 2 3 tensor(1414.8884, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 2 4 tensor(1281.1135, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 2 5 tensor(1098.3793, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 2 6 tensor(1042.2140, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 2 7 tensor(1022.2482, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 2 8 tensor(797.5427, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 2 9 tensor(450.3637, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 2 10 tensor(257.5185, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 2 11 tensor(0., device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 2 0 tensor(541.4871, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 2 1 tensor(519.7949, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 2 2 tensor(504.5787, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 2 3 tensor(482.1679, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 2 4 tensor(459.2005, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 2 5 tensor(431.5033, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 2 6 tensor(389.2926, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 2 7 tensor(355.4404, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 2 8 tensor(313.1591, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 2 9 tensor(251.5218, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 2 10 tensor(155.4733, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 2 11 tensor(0., device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 3 0 tensor(775.8147, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 3 1 tensor(742.8889, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 3 2 tensor(698.4252, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 3 3 tensor(637.6348, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 3 4 tensor(596.4429, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 3 5 tensor(564.9210, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 3 6 tensor(519.6108, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 3 7 tensor(448.0837, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 3 8 tensor(386.5506, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 3 9 tensor(309.3852, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 3 10 tensor(217.6856, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 3 11 tensor(0., device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 3 0 tensor(1234.0558, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 3 1 tensor(1194.0739, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 3 2 tensor(1095.5867, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 3 3 tensor(1004.8343, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 3 4 tensor(979.0527, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 3 5 tensor(950.8937, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 3 6 tensor(853.8127, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 3 7 tensor(708.8156, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 3 8 tensor(572.2950, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 3 9 tensor(441.4193, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 3 10 tensor(381.6881, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 3 11 tensor(0., device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 3 0 tensor(372.6108, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 3 1 tensor(356.0095, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 3 2 tensor(343.4015, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 3 3 tensor(325.6715, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 3 4 tensor(290.4423, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 3 5 tensor(258.3562, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 3 6 tensor(238.4264, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 3 7 tensor(211.0891, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 3 8 tensor(179.4781, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 3 9 tensor(156.6798, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 3 10 tensor(94.2692, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 3 11 tensor(0., device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 4 0 tensor(889.8433, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 4 1 tensor(856.3015, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 4 2 tensor(827.5077, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 4 3 tensor(792.9464, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 4 4 tensor(762.2988, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 4 5 tensor(719.5999, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 4 6 tensor(691.0959, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 4 7 tensor(656.9972, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 4 8 tensor(613.1885, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 4 9 tensor(573.4809, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 4 10 tensor(525.4492, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 4 11 tensor(0., device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 4 0 tensor(1507.1730, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 4 1 tensor(1462.9830, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 4 2 tensor(1439.2996, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 4 3 tensor(1389.3804, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 4 4 tensor(1365.2682, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 4 5 tensor(1322.5673, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 4 6 tensor(1297.0795, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 4 7 tensor(1264.3317, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 4 8 tensor(1239.8582, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 4 9 tensor(1205.6212, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 4 10 tensor(1179.3175, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 4 11 tensor(0., device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 4 0 tensor(428.8240, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 4 1 tensor(417.6447, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 4 2 tensor(400.0195, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 4 3 tensor(388.4673, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 4 4 tensor(351.5944, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 4 5 tensor(335.4041, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 4 6 tensor(302.9423, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 4 7 tensor(274.0983, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 4 8 tensor(226.3327, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 4 9 tensor(200.0283, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 4 10 tensor(105.2250, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 4 11 tensor(0., device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 5 0 tensor(946.7419, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 5 1 tensor(833.0608, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 5 2 tensor(794.2391, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 5 3 tensor(766.8793, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 5 4 tensor(729.4801, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 5 5 tensor(625.5217, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 5 6 tensor(568.3689, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 5 7 tensor(506.7372, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 5 8 tensor(390.9436, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 5 9 tensor(306.0578, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 5 10 tensor(224.0993, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 5 11 tensor(0., device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 5 0 tensor(909.3877, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 5 1 tensor(874.9673, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 5 2 tensor(819.2727, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 5 3 tensor(761.7457, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 5 4 tensor(691.6415, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 5 5 tensor(660.7896, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 5 6 tensor(575.9728, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 5 7 tensor(478.5351, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 5 8 tensor(423.3381, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 5 9 tensor(369.9471, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 5 10 tensor(218.0672, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 5 11 tensor(0., device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 5 0 tensor(485.2197, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 5 1 tensor(443.3801, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 5 2 tensor(433.5207, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 5 3 tensor(417.9078, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 5 4 tensor(400.8784, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 5 5 tensor(374.1007, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 5 6 tensor(339.8047, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 5 7 tensor(315.0839, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 5 8 tensor(288.8925, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 5 9 tensor(193.9277, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 5 10 tensor(160.2536, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 5 11 tensor(0., device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 6 0 tensor(831.8159, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 6 1 tensor(786.4587, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 6 2 tensor(756.8364, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 6 3 tensor(725.4775, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 6 4 tensor(701.0292, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 6 5 tensor(664.4947, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 6 6 tensor(622.6205, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 6 7 tensor(590.4131, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 6 8 tensor(547.7808, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 6 9 tensor(343.9365, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 6 10 tensor(210.7235, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 6 11 tensor(0., device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 6 0 tensor(841.0999, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 6 1 tensor(784.3743, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 6 2 tensor(757.3734, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 6 3 tensor(722.7794, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 6 4 tensor(678.4399, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 6 5 tensor(643.4880, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 6 6 tensor(605.6202, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 6 7 tensor(547.9736, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 6 8 tensor(452.5312, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 6 9 tensor(388.9441, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 6 10 tensor(322.6952, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 6 11 tensor(0., device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 6 0 tensor(496.4828, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 6 1 tensor(474.7346, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 6 2 tensor(443.6290, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 6 3 tensor(426.3867, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 6 4 tensor(405.7731, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 6 5 tensor(379.8151, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 6 6 tensor(332.4072, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 6 7 tensor(310.9261, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 6 8 tensor(290.6501, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 6 9 tensor(212.3642, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 6 10 tensor(114.4506, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 6 11 tensor(0., device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 7 0 tensor(889.1323, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 7 1 tensor(853.0995, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 7 2 tensor(777.9852, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 7 3 tensor(744.9332, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 7 4 tensor(711.3005, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 7 5 tensor(680.3685, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 7 6 tensor(645.8253, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 7 7 tensor(587.2282, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 7 8 tensor(543.9702, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 7 9 tensor(488.1114, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 7 10 tensor(320.6621, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 7 11 tensor(0., device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 7 0 tensor(837.3259, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 7 1 tensor(798.5180, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 7 2 tensor(757.4563, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 7 3 tensor(718.0798, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 7 4 tensor(663.3662, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 7 5 tensor(609.2582, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 7 6 tensor(577.2690, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 7 7 tensor(527.8936, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 7 8 tensor(437.7563, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 7 9 tensor(329.8654, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 7 10 tensor(205.1738, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 7 11 tensor(0., device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 7 0 tensor(595.5563, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 7 1 tensor(573.2657, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 7 2 tensor(514.7050, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 7 3 tensor(485.2253, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 7 4 tensor(465.8595, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 7 5 tensor(444.2417, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 7 6 tensor(387.7707, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 7 7 tensor(350.5357, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 7 8 tensor(326.3635, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 7 9 tensor(276.4149, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 7 10 tensor(186.6578, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 7 11 tensor(0., device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 8 0 tensor(804.9030, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 8 1 tensor(746.7071, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 8 2 tensor(711.7748, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 8 3 tensor(662.6770, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 8 4 tensor(620.0973, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 8 5 tensor(584.8016, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 8 6 tensor(519.0960, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 8 7 tensor(462.4863, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 8 8 tensor(405.5333, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 8 9 tensor(338.8221, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 8 10 tensor(253.7668, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 8 11 tensor(0., device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 8 0 tensor(875.6031, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 8 1 tensor(833.3417, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 8 2 tensor(800.0360, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 8 3 tensor(751.0027, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 8 4 tensor(687.0527, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 8 5 tensor(628.0620, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 8 6 tensor(570.2935, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 8 7 tensor(483.0242, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 8 8 tensor(402.4358, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 8 9 tensor(340.1999, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 8 10 tensor(251.5788, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 8 11 tensor(0., device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 8 0 tensor(615.3828, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 8 1 tensor(573.2870, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 8 2 tensor(544.6209, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 8 3 tensor(521.8013, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 8 4 tensor(497.7961, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 8 5 tensor(479.3724, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 8 6 tensor(437.5365, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 8 7 tensor(417.3527, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 8 8 tensor(382.3535, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 8 9 tensor(339.0482, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 8 10 tensor(249.6980, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 8 11 tensor(0., device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 9 0 tensor(888.2387, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 9 1 tensor(842.3070, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 9 2 tensor(813.3316, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 9 3 tensor(778.0084, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 9 4 tensor(719.0916, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 9 5 tensor(679.8675, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 9 6 tensor(614.9576, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 9 7 tensor(543.4792, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 9 8 tensor(492.8070, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 9 9 tensor(385.1707, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 9 10 tensor(284.6461, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 9 11 tensor(0., device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 9 0 tensor(898.7084, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 9 1 tensor(852.4177, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 9 2 tensor(811.8242, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 9 3 tensor(754.3365, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 9 4 tensor(707.2305, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 9 5 tensor(673.4659, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 9 6 tensor(614.9593, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 9 7 tensor(569.2770, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 9 8 tensor(506.6442, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 9 9 tensor(397.9028, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 9 10 tensor(250.6125, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 9 11 tensor(0., device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 9 0 tensor(760.9066, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 9 1 tensor(709.0588, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 9 2 tensor(682.8801, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 9 3 tensor(666.9739, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 9 4 tensor(643.6790, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 9 5 tensor(598.9258, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 9 6 tensor(533.6300, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 9 7 tensor(484.7330, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 9 8 tensor(442.6679, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 9 9 tensor(307.5339, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 9 10 tensor(265.2848, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 9 11 tensor(0., device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 10 0 tensor(920.2748, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 10 1 tensor(867.9531, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 10 2 tensor(819.8597, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 10 3 tensor(773.6337, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 10 4 tensor(724.0739, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 10 5 tensor(667.2435, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 10 6 tensor(614.5507, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 10 7 tensor(561.4147, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 10 8 tensor(471.7401, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 10 9 tensor(395.0963, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 10 10 tensor(268.9774, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 10 11 tensor(0., device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 10 0 tensor(981.1562, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 10 1 tensor(931.5374, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 10 2 tensor(890.3798, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 10 3 tensor(842.2986, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 10 4 tensor(795.9581, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 10 5 tensor(746.4077, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 10 6 tensor(678.9313, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 10 7 tensor(600.7723, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 10 8 tensor(545.1645, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 10 9 tensor(437.4381, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 10 10 tensor(330.6678, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 10 11 tensor(0., device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 10 0 tensor(845.3891, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 10 1 tensor(803.8168, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 10 2 tensor(742.3350, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 10 3 tensor(700.7585, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 10 4 tensor(666.2702, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 10 5 tensor(629.8585, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 10 6 tensor(567.6956, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 10 7 tensor(472.5430, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 10 8 tensor(400.2635, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 10 9 tensor(352.7812, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 10 10 tensor(189.7181, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 10 11 tensor(0., device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 11 0 tensor(1201.8376, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 11 1 tensor(1145.1980, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 11 2 tensor(1100.0107, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 11 3 tensor(1027.7783, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 11 4 tensor(983.6879, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 11 5 tensor(922.0885, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 11 6 tensor(856.9633, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 11 7 tensor(781.1129, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 11 8 tensor(661.5445, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 11 9 tensor(554.8142, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 11 10 tensor(407.3301, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "q 11 11 tensor(0., device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 11 0 tensor(986.8204, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 11 1 tensor(950.8495, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 11 2 tensor(906.6858, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 11 3 tensor(869.3032, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 11 4 tensor(830.1837, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 11 5 tensor(779.8845, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 11 6 tensor(728.8922, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 11 7 tensor(673.7712, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 11 8 tensor(526.6190, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 11 9 tensor(435.5793, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 11 10 tensor(303.1491, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "k 11 11 tensor(0., device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 11 0 tensor(1366.4883, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 11 1 tensor(1338.7219, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 11 2 tensor(1301.6759, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 11 3 tensor(1290.5513, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 11 4 tensor(1264.6633, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 11 5 tensor(1232.9259, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 11 6 tensor(1200.3845, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 11 7 tensor(1172.0236, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 11 8 tensor(415.1159, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 11 9 tensor(315.5089, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 11 10 tensor(220.4718, device='cuda:0', grad_fn=<NormBackward1>)\n",
      "v 11 11 tensor(0., device='cuda:0', grad_fn=<NormBackward1>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-0.0638, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_value_dict = {}\n",
    "for layer_index, layer in enumerate(gpt2_masked.blocks):\n",
    "    for head_index in range(12):\n",
    "        for q_k_v in [\"q\", \"k\", \"v\"]:\n",
    "            # total_nodes += 1\n",
    "            if q_k_v == \"q\":\n",
    "                mask_value = (\n",
    "                    layer.attn.hook_q.sample_mask()[head_index].cpu().item()\n",
    "                )\n",
    "            if q_k_v == \"k\":\n",
    "                mask_value = (\n",
    "                    layer.attn.hook_k.sample_mask()[head_index].cpu().item()\n",
    "                )\n",
    "            if q_k_v == \"v\":\n",
    "                mask_value = (\n",
    "                    layer.attn.hook_v.sample_mask()[head_index].cpu().item()\n",
    "                )\n",
    "            mask_value_dict[f\"{layer_index}.{head_index}.{q_k_v}\"] = mask_value\n",
    "\n",
    "mask_value_dict.values()\n",
    "forward_hooks = make_forward_hooks(mask_value_dict)\n",
    "logit_diff_from_ioi_dataset(new_gpt2.run_with_hooks(train_data, return_type=\"logits\", fwd_hooks=forward_hooks), train_data, mean=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('blocks.0.attn.hook_q',\n",
       " functools.partial(<function make_forward_hooks.<locals>.head_ablation_hook at 0x7f0a51c0beb0>, head_idx=0, layer_idx=0, qkv_val='q'))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_hooks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6ad467ea6ce724cf68e3e9460a7b5d30a577b9574f7d768503ed98371d079a52"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
